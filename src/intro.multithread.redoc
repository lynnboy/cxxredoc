[section#intro.multithread
    [:en] Multi-threaded executions and data races
    [:zh_CN] 多线程执行与数据竞争
]

[index:begin#threads.multiple
    [:en] threads [!multiple]
    [:zh_CN] 线程 [!多～]
]

[index:begin#operation.atomic
    [:en] operation [!atomic]
    [:zh_CN] 操作 [!原子性～]
]

[para]
[:en]
A [def thread of execution] (also known as a [defn thread]) is a single flow of
control within a program, including the initial invocation of a specific
top-level function, and recursively including every function invocation
subsequently executed by the thread.
[:zh_CN]
[def 执行线程]（又称[def 线程]）是程序中单独的控制流，它包括对某个特定的顶层
函数的起始调用，以及递归地包括该线程随后所执行的每个函数调用。

[enter:note]
[:en]
When one thread creates another, the initial call to the top-level function of
the new thread is executed by the new thread, not by the creating thread.
[:zh_CN]
当一个线程创建另一个线程时，对新线程的顶层函数的起始调用，是被新线程而不是创建
它的线程所执行的。
[exit:note]

[:en]
Every thread in a program can potentially access every object and function in
a program.
[:zh_CN]
程序中的每个线程均潜在地可以访问程序中的每个对象和函数。

[footnote]
[:en]
An object with automatic or thread storage duration ([#basic.stc]) is associated
with one specific thread, and can be accessed by a different thread only
indirectly through a pointer or reference ([#basic.compound]).
[:zh_CN]
具有自动或线程存储期（[#basic.stc]）的对象与某个特定线程相关联，而其他线程仅能
通过指针或引用（[#basic.compound]）间接地进行访问。
[footnote:end]

[:en]
Under a hosted implementation, a [=Cpp] program can have more than one thread
running concurrently.
[:zh_CN]
在宿主式实现中，[=Cpp] 程序可以具有多个同时运行的线程。

[:en]
The execution of each thread proceeds as defined by the remainder of this
standard.
[:zh_CN]
每个线程都按照本标准其余部分的定义来执行。

[:en]
The execution of the entire program consists of an execution of all of its
threads.
[:zh_CN]
整个程序的执行则由它的所有线程的执行构成。

[enter:note]
[:en]
Usually the execution can be viewed as an interleaving of all its threads.
[:zh_CN]
通常可以将其执行过程视为它的所有线程的交错执行。

[:en]
However, some kinds of atomic operations, for example, allow executions
inconsistent with a simple interleaving, as described below.
[:zh_CN]
然而，（比如）某些种类的原子性操作，将允许其执行并不符合单纯的交错执行，
如下所述。
[exit:note]

[:en]
Under a freestanding implementation, it is [%@impldef number of threads in a
program under a freestanding implementation] implementation-defined whether a
program can have more than one thread of execution.
[:zh_CN]
在自立式实现中，[%@impldef 自立式实现下程序中的线程数]由实现定义程序是否可以
具有多个执行线程。

[para]
[:en]
A signal handler that is executed as a result of a call to the [`raise] function
belongs to the same thread of execution as the call to the [`raise] function.
[:zh_CN]
由于调用[`raise]函数而执行的信号处理器属于对[`raise]函数的调用同一个执行线程。

[:en]
Otherwise it is unspecified which thread of execution contains a signal handler
invocation.
[:zh_CN]
否则，哪个执行线程包含对信号处理器的调用是未指明的。

[para]
[:en]
Implementations should ensure that all unblocked threads eventually make
progress.
[:zh_CN]
实现应当保证所有未阻塞线程最终都将继续前进。

[enter:note]
[:en]
Standard library functions may silently block on I/O or locks.
[:zh_CN]
标准程序库中的函数可能会默默地在 I/O 或锁上阻塞。

[:en]
Factors in the execution environment, including externally-imposed thread
priorities, may prevent an implementation from making certain guarantees of
forward progress.
[:zh_CN]
而执行环境中的因素，包括由外部施加的线程优先级等，可能会阻碍实现做出推进前进的
特定保证。
[exit:note]

[para]
[:en]
Executions of atomic functions that are either defined to be lock-free
([#atomics.flag]) or indicated as lock-free ([#atomics.lockfree])
are [def lock-free executions].
[:zh_CN]
被定义为无锁的（[#atomics.flag]），或者被标示为无锁的（[#atomics.lockfree]）
原子性函数的执行，是[def 无锁执行]。

[list:ul]

[item]
[:en]
If there is only one unblocked thread, a lock-free execution in that thread
shall complete.
[:zh_CN]
如果只有一个未阻塞线程，则该线程中的无锁执行应当能够执行完毕。

[enter:note]
[:en]
Concurrently executing threads may prevent progress of a lock-free execution.
[:zh_CN]
并发执行的线程可能会妨碍无锁执行的进程。

[:en]
For example, this situation can occur with load-locked store-conditional
implementations.
[:zh_CN]
例如，LL/SC（Load-Locked Store-Conditional）实现中可能出现此种情况。

[:en]
This property is sometimes termed obstruction-free.
[:zh_CN]
这种性质经常被称为“无阻碍”。
[exit:note]

[item]
[:en]
When one or more lock-free executions run concurrently, at least one should
complete.
[:zh_CN]
当同时运行一个或多个无锁执行时，至少其中之一应当能够执行完毕。

[enter:note]
[:en]
It is difficult for some implementations to provide absolute guarantees to this
effect, since repeated and particularly inopportune interference from other
threads may prevent forward progress,
[:zh_CN]
某些实现中难于为这种效果提供绝对保障，这是由于其他线程中重复发生的特别不合时宜
的干扰可能妨碍其进程，

[:en]
e.g., by repeatedly stealing a cache line for unrelated purposes between
load-locked and store-conditional instructions.
[:zh_CN]
例如，通过不断地在LL（Load-Locked）和SC（Store-Conditional）指令之间偷取
某个用于无关目的的Cache Line。

[:en]
Implementations should ensure that such effects cannot indefinitely delay
progress under expected operating conditions, and that such anomalies can
therefore safely be ignored by programmers.
[:zh_CN]
实现应当保证，这种效应在预期的操作条件下不能无限期地延迟进程，由此程序员可以
安全地忽略这种反常情况。

[:en]
Outside this International Standard, this property is sometimes termed lock-free.
[:zh_CN]
本国际标准之外，这种性质常被称为“无锁”。
[exit:note]

[list:end]

[para]
[:en]
The value of an object visible to a thread [$T] at a particular point is the
initial value of the object, a value assigned to the object by [$T], or a
value assigned to the object by another thread, according to the rules below.
[:zh_CN]
根据如下规则，某个对象对某个线程 [$T] 在某特定点可见的值，是该对象的初始值，由
[$T] 赋给该对象的值，或者由其他线程赋给该对象的值。

[enter:note]
[:en]
In some cases, there may instead be undefined behavior.
[:zh_CN]
某些情况下，也可能造成未定义的行为。

[:en]
Much of this section is motivated by the desire to support atomic operations
with explicit and detailed visibility constraints.
[:zh_CN]
本节中的多数内容的动机是希望通过明确并详细的可见性约束来支持原子性操作。

[:en]
However, it also implicitly supports a simpler view for more restricted programs.
[:zh_CN]
然而，这也隐含地对更受限制的程序提供了一种简化的视角。
[exit:note]

[para]
[:en]
Two expression evaluations [def conflict] if one of them modifies a memory
location ([#intro.memory]) and the other one reads or modifies the same memory
location.
[:zh_CN]
如果两个表达式的求值其中之一改动了某个内存位置（[#intro.memory]），而另一个读取
或改动了同一个内存位置，则它们发生[def 冲突]。

[para]
[:en]
The library defines a number of atomic operations (Clause [#atomics]) and
operations on mutexes (Clause [#thread]) that are specially identified as
synchronization operations.
[:zh_CN]
程序库中定义了许多原子性操作（第 [#atomics] 条）和在互斥体上的操作（第 [#thread]
条），它们被特别当作同步操作。

[:en]
These operations play a special role in making assignments in one thread visible
to another.
[:zh_CN]
这些操作在使一个线程中的赋值对另一个线程可见时起到特殊的作用。

[:en]
A synchronization operation on one or more memory locations is either a consume
operation, an acquire operation, a release operation, or both an acquire and
release operation.
[:zh_CN]
对一个或多个内存位置的同步操作，可以是消费操作、获取操作、释放操作或者获取并
释放操作。

[:en]
A synchronization operation without an associated memory location is a fence and
can be either an acquire fence, a release fence, or both an acquire and release
fence.
[:zh_CN]
没有关联的内存位置的同步操作是内存栅栏，可以是获取栅栏、释放栅栏或获取并释放栅栏。

[:en]
In addition, there are relaxed atomic operations, which are not synchronization
operations, and atomic read-modify-write operations, which have special
characteristics.
[:zh_CN]
此外，还有不是同步操作的弱原子性操作，以及具有特殊性质的原子性读-改-写操作。

[enter:note]
[:en]
For example, a call that acquires a mutex will perform an acquire operation on
the locations comprising the mutex.
[:zh_CN]
例如，获取一个互斥体的函数调用对构成该互斥体的内存位置施以获取操作。

[:en]
Correspondingly, a call that releases the same mutex will perform a release
operation on those same locations.
[:zh_CN]
相应地，释放同一个互斥体的函数调用对这些内存位置施以释放操作。

[:en]
Informally, performing a release operation on [$A] forces prior [%side effects]
side effects on other memory locations to become visible to other threads that
later perform a consume or an acquire operation on [$A].
[:zh_CN]
非正式地说，对 [$A] 施以释放操作，将促使此前在其他内存位置上的[%副作用]副作用，
对于此后对 [$A] 施以消费或获取操作的其他线程变为可见。

[:en]
["Relaxed] atomic operations are not synchronization operations even
though, like synchronization operations, they cannot contribute to data races.
[:zh_CN]

[exit:note]

\pnum
All modifications to a particular atomic object \term{M} occur in some
particular total order, called the \defn{modification order} of \term{M}. If
\term{A} and \term{B} are modifications of an atomic object \term{M} and
\term{A} happens before (as defined below) \term{B}, then \term{A} shall precede
\term{B} in the modification order of \term{M}, which is defined below.
\enternote This states that the modification orders must respect the ``happens
before'' relationship. \exitnote \enternote There is a separate order for each
atomic object. There is no requirement that these can be combined into a single
total order for all objects. In general this will be impossible since different
threads may observe modifications to different objects in inconsistent orders.
\exitnote

\pnum
A \defn{release sequence} headed by a release operation \term{A} on an atomic object
\term{M} is a maximal contiguous sub-sequence of
\indextext{side effects}%
side effects in the
modification order of \term{M}, where the first operation is \tcode{A}, and
every subsequent operation

\begin{itemize}
\item is performed by the same thread that performed \tcode{A}, or
\item is an atomic read-modify-write operation.
\end{itemize}

\pnum
Certain library calls \defn{synchronize with} other library calls performed by
another thread. For example, an atomic store-release synchronizes with a
load-acquire that takes its value from the store~(\ref{atomics.order}).
\enternote Except in the specified cases, reading a later value does not
necessarily ensure visibility as described below. Such a requirement would
sometimes interfere with efficient implementation. \exitnote \enternote The
specifications of the synchronization operations define when one reads the value
written by another. For atomic objects, the definition is clear. All operations
on a given mutex occur in a single total order. Each mutex acquisition ``reads
the value written'' by the last mutex release. \exitnote

\pnum
An evaluation \term{A} \defn{carries a dependency} to an evaluation \term{B} if

\begin{itemize}

\item
the value of \term{A} is used as an operand of \term{B}, unless:
\begin{itemize}

\item
\term{B} is an invocation of any specialization of
\tcode{std::kill_dependency}~(\ref{atomics.order}), or

\item
\term{A} is the left operand of a built-in logical AND (\tcode{\&\&},
see~\ref{expr.log.and}) or logical OR (\tcode{||}, see~\ref{expr.log.or})
operator, or

\item
\term{A} is the left operand of a conditional (\tcode{?:}, see~\ref{expr.cond})
operator, or

\item
\term{A} is the left operand of the built-in comma (\tcode{,})
operator~(\ref{expr.comma}); \end{itemize} or

\item
\term{A} writes a scalar object or bit-field \term{M}, \term{B} reads the value
written by \term{A} from \term{M}, and \term{A} is sequenced before \term{B}, or

\item
for some evaluation \term{X}, \term{A} carries a dependency to \term{X}, and
\term{X} carries a dependency to \term{B}.

\end{itemize}

\enternote ``Carries a dependency to'' is a subset of ``is sequenced before'',
and is similarly strictly intra-thread. \exitnote

\pnum
An evaluation \term{A} is \defn{dependency-ordered before} an evaluation
\term{B} if
\begin{itemize}

\item
\term{A} performs a release operation on an atomic object \term{M}, and, in
another thread, \term{B} performs a consume operation on \term{M} and reads a
value written by any
\indextext{side effects}%
side effect in the release sequence headed by \term{A}, or

\item
for some evaluation \term{X}, \term{A} is dependency-ordered before \term{X} and
\term{X} carries a dependency to \term{B}.

\end{itemize}
\enternote The relation ``is dependency-ordered before'' is analogous to
``synchronizes with'', but uses release/consume in place of release/acquire.
\exitnote

\pnum
An evaluation \term{A} \defn{inter-thread happens before} an evaluation \term{B}
if

\begin{itemize}

\item
\term{A} synchronizes with \term{B}, or

\item
\term{A} is dependency-ordered before \term{B}, or

\item
for some evaluation \term{X}

\begin{itemize}
\item
\term{A} synchronizes with \term{X} and \term{X} is sequenced before \term{B},
or

\item
\term{A} is sequenced before \term{X} and \term{X} inter-thread happens before
\term{B}, or

\item
\term{A} inter-thread happens before \term{X} and \term{X} inter-thread happens
before \term{B}.
\end{itemize}
\end{itemize}

\enternote The ``inter-thread happens before'' relation describes arbitrary
concatenations of ``sequenced before'', ``synchronizes with'' and
``dependency-ordered before'' relationships, with two exceptions. The first
exception is that a concatenation is not permitted to end with
``dependency-ordered before'' followed by ``sequenced before''. The reason for
this limitation is that a consume operation participating in a
``dependency-ordered before'' relationship provides ordering only with respect
to operations to which this consume operation actually carries a dependency. The
reason that this limitation applies only to the end of such a concatenation is
that any subsequent release operation will provide the required ordering for a
prior consume operation. The second exception is that a concatenation is not
permitted to consist entirely of ``sequenced before''. The reasons for this
limitation are (1) to permit ``inter-thread happens before'' to be transitively
closed and (2) the ``happens before'' relation, defined below, provides for
relationships consisting entirely of ``sequenced before''. \exitnote

\pnum
An evaluation \term{A} \defn{happens before} an evaluation \term{B} if:

\begin{itemize}
\item \term{A} is sequenced before \term{B}, or
\item \term{A} inter-thread happens before \term{B}.
\end{itemize}

The implementation shall ensure that no program execution demonstrates a cycle
in the ``happens before'' relation. \enternote This cycle would otherwise be
possible only through the use of consume operations. \exitnote

\pnum
A \defnx{visible side effect}{side effects!visible} \term{A} on a scalar object or bit-field \term{M}
with respect to a value computation \term{B} of \term{M} satisfies the
conditions:

\begin{itemize}
\item \term{A} happens before \term{B} and
\item there is no other
\indextext{side effects}%
side effect \term{X} to \term{M} such that \term{A}
happens before \term{X} and \term{X} happens before \term{B}.
\end{itemize}

The value of a non-atomic scalar object or bit-field \term{M}, as determined by
evaluation \term{B}, shall be the value stored by the
\indextext{side effects!visible}%
visible side effect
\term{A}. \enternote If there is ambiguity about which side effect to a
non-atomic object or bit-field is visible, then the behavior is either
unspecified or undefined. \exitnote \enternote This states that operations on
ordinary objects are not visibly reordered. This is not actually detectable
without data races, but it is necessary to ensure that data races, as defined
below, and with suitable restrictions on the use of atomics, correspond to data
races in a simple interleaved (sequentially consistent) execution. \exitnote

\pnum
The value of an
atomic object \term{M}, as determined by evaluation \term{B}, shall be the value
stored by some
side effect \term{A} that modifies \term{M}, where \term{B} does not happen
before \term{A}.
\enternote
The set of such side effects is also restricted by the rest of the rules
described here, and in particular, by the coherence requirements below.
\exitnote

\pnum
If an operation \term{A} that modifies an atomic object \term{M} happens before
an operation \term{B} that modifies \term{M}, then \term{A} shall be earlier
than \term{B} in the modification order of \term{M}. \enternote This requirement
is known as write-write coherence. \exitnote

\pnum
If a
\indextext{value computation}%
value computation \term{A} of an atomic object \term{M} happens before a
value computation \term{B} of \term{M}, and \term{A} takes its value from a side
effect \term{X} on \term{M}, then the value computed by \term{B} shall either be
the value stored by \term{X} or the value stored by a
\indextext{side effects}%
side effect \term{Y} on
\term{M}, where \term{Y} follows \term{X} in the modification order of \term{M}.
\enternote This requirement is known as read-read coherence. \exitnote

\pnum
If a
\indextext{value computation}%
value computation \term{A} of an atomic object \term{M} happens before an
operation \term{B} that modifies \term{M}, then \term{A} shall take its value from a side
effect \term{X} on \term{M}, where \term{X} precedes \term{B} in the
modification order of \term{M}. \enternote This requirement is known as
read-write coherence. \exitnote

\pnum
If a
\indextext{side effects}%
side effect \term{X} on an atomic object \term{M} happens before a value
computation \term{B} of \term{M}, then the evaluation \term{B} shall take its
value from \term{X} or from a
\indextext{side effects}%
side effect \term{Y} that follows \term{X} in the
modification order of \term{M}. \enternote This requirement is known as
write-read coherence. \exitnote

\pnum
\enternote The four preceding coherence requirements effectively disallow
compiler reordering of atomic operations to a single object, even if both
operations are relaxed loads. This effectively makes the cache coherence
guarantee provided by most hardware available to \Cpp atomic operations.
\exitnote

\pnum
\enternote The value observed by a load of an atomic depends on the ``happens
before'' relation, which depends on the values observed by loads of atomics.
The intended reading is that there must exist an
association of atomic loads with modifications they observe that, together with
suitably chosen modification orders and the ``happens before'' relation derived
as described above, satisfy the resulting constraints as imposed here. \exitnote

\pnum
\indextext{potentially~concurrent}%
Two actions are \term{potentially concurrent} if
\begin{itemize}
\item they are performed by different threads, or
\item they are unsequenced, and at least one is performed by a signal handler.
\end{itemize}
\indextext{data~race}%
The execution of a program contains a \defn{data race} if it contains two
potentially concurrent conflicting actions, at least one of which is not atomic,
and neither happens before the other,
except for the special case for signal handlers described below.
Any such data race results in undefined
behavior. \enternote It can be shown that programs that correctly use mutexes
and \tcode{memory_order_seq_cst} operations to prevent all data races and use no
other synchronization operations behave as if the operations executed by their
constituent threads were simply interleaved, with each
\indextext{value computation}%
value computation of an
object being taken from the last
\indextext{side effects}%
side effect on that object in that
interleaving. This is normally referred to as ``sequential consistency''.
However, this applies only to data-race-free programs, and data-race-free
programs cannot observe most program transformations that do not change
single-threaded program semantics. In fact, most single-threaded program
transformations continue to be allowed, since any program that behaves
differently as a result must perform an undefined operation. \exitnote

\pnum
Two accesses to the same object of type \tcode{volatile sig_atomic_t} do not
result in a data race if both occur in the same thread, even if one or more
occurs in a signal handler. For each signal handler invocation, evaluations
performed by the thread invoking a signal handler can be divided into two
groups \placeholder{A} and \placeholder{B}, such that no evaluations in
\placeholder{B} happen before evaluations in \placeholder{A}, and the
evaluations of such \tcode{volatile sig_atomic_t} objects take values as though
all evaluations in \placeholder{A} happened before the execution of the signal
handler and the execution of the signal handler happened before all evaluations
in \placeholder{B}.

\pnum
\enternote Compiler transformations that introduce assignments to a potentially
shared memory location that would not be modified by the abstract machine are
generally precluded by this standard, since such an assignment might overwrite
another assignment by a different thread in cases in which an abstract machine
execution would not have encountered a data race. This includes implementations
of data member assignment that overwrite adjacent members in separate memory
locations. Reordering of atomic loads in cases in which the atomics in question
may alias is also generally precluded, since this may violate the coherence
rules. \exitnote

\pnum
\enternote Transformations that introduce a speculative read of a potentially
shared memory location may not preserve the semantics of the \Cpp program as
defined in this standard, since they potentially introduce a data race. However,
they are typically valid in the context of an optimizing compiler that targets a
specific machine with well-defined semantics for data races. They would be
invalid for a hypothetical machine that is not tolerant of races or provides
hardware race detection. \exitnote

\pnum
The implementation may assume that any thread will eventually do one of the
following:

\begin{itemize}
\item
terminate,

\item
make a call to a library I/O function,

\item
read or modify a volatile object, or

\item
perform a synchronization operation or an atomic operation.
\end{itemize}

\enternote This is intended to allow compiler transformations such as removal of
empty loops, even when termination cannot be proven. \exitnote

\pnum
An implementation should ensure that the last value (in modification order)
assigned by an atomic or synchronization operation will become visible to all
other threads in a finite period of time.%

[index:end#operation.atomic]

[index:end#threads.multiple]
